version: '3'

services:
  hadoop-namenode:
    hostname: hadoop-namenode
    build: ./hadoop-container-build
    ports:
      - "9000:9000"
      - "9080:8080"
      - "9870:9870"
      - "50071:50070"
    networks:
#      - hadoop-network
      - spark_spark-network
    command:
      ./hadoop/hadoop-2.8.1/run.sh
#     ./hadoop/hadoop-2.8.1/bin/hdfs namenode -format hadoop-cluster -Y && ./hadoop/hadoop-2.8.1/bin/hdfs namenode
  hadoop-datanode_1:
    hostname: hadoop-datanode1
    build: ./hadoop-container-build
    ports:
      - "9081:8080"
    networks:
#      - hadoop-network
      - spark_spark-network
    command:
     ./hadoop/hadoop-2.8.1/bin/hdfs datanode

  hadoop-datanode_2:
    hostname: hadoop-datanode2
    build: ./hadoop-container-build
    ports:
      - "9082:8080"
    networks:
#      - hadoop-network
      - spark_spark-network
    command:
     ./hadoop/hadoop-2.8.1/bin/hdfs datanode

  hadoop-datanode_3:
    hostname: hadoop-datanode3
    build: ./hadoop-container-build
    ports:
      - "9083:8080"
    networks:
#      - hadoop-network
      - spark_spark-network
    command:
     ./hadoop/hadoop-2.8.1/bin/hdfs datanode

#  hadoop-slave:
#    build: ./hadoop-container-build
#    ports:
#      - "8081:8080"
#    networks:
#      - hadoop-network

networks:
  spark_spark-network:
    external: true

#  hadoop-network:
